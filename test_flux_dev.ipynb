{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/image/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...:  43%|████▎     | 3/7 [00:03<00:04,  1.01s/it]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FluxPipeline {\n",
       "  \"_class_name\": \"FluxPipeline\",\n",
       "  \"_diffusers_version\": \"0.30.3\",\n",
       "  \"_name_or_path\": \"black-forest-labs/FLUX.1-schnell\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"FlowMatchEulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5TokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"FluxTransformer2DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16)\n",
    "pipe.to(\"cuda\")\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "pipe.vae.enable_slicing()\n",
    "pipe.vae.enable_tiling()\n",
    "pipe.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from diffusers import FluxPipeline\n",
    "\n",
    "# # Create the pipeline\n",
    "# pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16)\n",
    "# pipe.to(\"cuda\")\n",
    "# # Enable CPU offloading to save VRAM (remove this line if you have enough GPU memory)\n",
    "# pipe.enable_model_cpu_offload()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:24<00:00,  6.17s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up your prompt\n",
    "# prompt = \"A graph of normal distribution. The y-axis is given a name f(x) and x-axis is given the name 'X'. The scale of x-axis is between -1 to +1\"\n",
    "prompt = \"The graph of projection of Y vector onto the columnspace of X in Linear regression. The image should contain a vector with name Y, a plane with name X and another vector y_bar in the plane X.\"\n",
    "\n",
    "# Generate the image\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    guidance_scale=0.0,\n",
    "    num_inference_steps=4,\n",
    "    max_sequence_length=256,\n",
    "    generator=torch.Generator(\"cuda\").manual_seed(0)\n",
    ").images[0]\n",
    "\n",
    "# Save the generated image\n",
    "image.save(\"flux_sample2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377213425bbe460292e762c57eef313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247ccb8c164d4716ae51c9ba8ae9104b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FluxPipeline {\n",
       "  \"_class_name\": \"FluxPipeline\",\n",
       "  \"_diffusers_version\": \"0.30.3\",\n",
       "  \"_name_or_path\": \"black-forest-labs/FLUX.1-schnell\",\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"FlowMatchEulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5EncoderModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"T5TokenizerFast\"\n",
       "  ],\n",
       "  \"transformer\": [\n",
       "    \"diffusers\",\n",
       "    \"FluxTransformer2DModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from together import Together\n",
    "api_key = os.getenv(\"together_api_key\")\n",
    "client = Together(api_key=api_key)\n",
    "import torch\n",
    "from diffusers import FluxPipeline\n",
    "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16)\n",
    "pipe.to(\"cuda\")\n",
    "pipe.enable_sequential_cpu_offload()\n",
    "pipe.vae.enable_slicing()\n",
    "pipe.vae.enable_tiling()\n",
    "pipe.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_text_description(input):\n",
    "\n",
    "    prompts = f'''\n",
    "    You are University level professor with extensive knowledge.\n",
    "    Your task is to give a brief and appropriate description of the user's input topic, by breaking down into simpler terms.\n",
    "\n",
    "    Prioritize clarity and brevity. Your response must not exceed 250 words.\n",
    "\n",
    "    User input: {input}\n",
    "    Output:\n",
    "    '''\n",
    "\n",
    "    client = Together(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompts}],\n",
    "    )\n",
    "\n",
    "    # Extract the selected option from the response\n",
    "    response = response.choices[0].message.content.strip()\n",
    "    return response\n",
    "\n",
    "def get_text_instructions(input):\n",
    "\n",
    "    prompts = f'''\n",
    "    You are a mathematical visualization expert. Create concise, precise instructions for generating a mathematical image based on the user's input.\n",
    "    \n",
    "        Include only:\n",
    "        1. Graph type: Specify the exact type of graph.\n",
    "        2. Essential equation(s): Provide the main formula(s) to plot, ```DATA POINTS TO BE PLOTTED.```\n",
    "        3. Axis labels and ranges: Use standard terms (x, y, z, t) and specify exact numerical ranges.\n",
    "        4. Key features: List only critical points, intersections, or regions crucial to understanding the graph.\n",
    "        5. Color scheme: Suggest up to two colors for clarity, if necessary.\n",
    "\n",
    "        Omit any explanatory text. Use mathematical notation where appropriate. Limit your response to 100 words.\n",
    "\n",
    "        User input: {input}\n",
    "        Output:\n",
    "\n",
    "    '''\n",
    "\n",
    "    client = Together(api_key=api_key)\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompts}],\n",
    "    )\n",
    "\n",
    "    # Extract the selected option from the response\n",
    "    response = response.choices[0].message.content.strip()\n",
    "    return response\n",
    "\n",
    "\n",
    "def image_gen_fxn(input_prompt):\n",
    "    input_prompt = f'{input_prompt} with the axis plotted and labelled.'\n",
    "    image = pipe(\n",
    "        input_prompt,\n",
    "        guidance_scale=0.0,\n",
    "        num_inference_steps=4,\n",
    "        max_sequence_length=256,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(0)\n",
    "        ).images[0]\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def generate_text_and_image(user_input):\n",
    "\n",
    "    text_output = get_text_description(input=user_input)\n",
    "    # text_instructions = get_text_instructions(input=user_input)\n",
    "    image_output = image_gen_fxn(input_prompt=user_input)\n",
    "\n",
    "    return text_output, image_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:6006\n",
      "Running on public URL: https://65d5c5ccb41a05e12a.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://65d5c5ccb41a05e12a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec67366e66b4020abfb429bceceaa88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f496cd32b7349239eec6d7d7bef3c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfaa4e8a1ac40cabd2dc9018bb4a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34eaeafe34f432da9847dce25ef4131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725dd56ce07748a1a6ed032f2ed7ab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3691ef8306e24c899df57e61e2e4dd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c9d413f07a42b1b3a1286e00074f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919afd58af584bd5b8702712fe58dba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8447dd479ad241aebcc2cda44e63c07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9afce1e0f2b47c0b306c0fc99e83453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Create Gradio interface\n",
    "# with gr.Blocks(theme=\"default\") as iface:\n",
    "#     gr.Markdown(\"# EduGraphix\")\n",
    "#     gr.Markdown(\"What are you exploring today? Let us enhance your journey with visual aids!\")\n",
    "    \n",
    "#     with gr.Row():\n",
    "#         with gr.Column(scale=1):\n",
    "#             input_text = gr.Textbox(label=\"Enter a prompt\", lines=5)\n",
    "#             # Small Submit Button below the input text box\n",
    "#             submit_button = gr.Button(\"Generate\", elem_id=\"submit-button\", size=\"small\")\n",
    "#         with gr.Column(scale=1):\n",
    "#             text_output = gr.Textbox(label=\"Textual Description\", lines=5)\n",
    "    \n",
    "#     with gr.Row():\n",
    "#         with gr.Column(scale=1, min_width=0):\n",
    "#             gr.Markdown(\"\")  # Empty column for spacing\n",
    "#         with gr.Column(scale=2):\n",
    "#             image_output = gr.Image(label=\"Generated Image\")\n",
    "#         with gr.Column(scale=1, min_width=0):\n",
    "#             gr.Markdown(\"\")  # Empty column for spacing\n",
    "    \n",
    "#     # Set up the button action\n",
    "#     submit_button.click(generate_text_and_image, inputs=input_text, outputs=[text_output, image_output])\n",
    "\n",
    "# # Add custom CSS to style the button smaller\n",
    "# iface.css = \"\"\"\n",
    "# #submit-button {\n",
    "#     padding: 5px 10px; /* Adjust padding for smaller size */\n",
    "#     font-size: 12px;   /* Smaller font size */\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# # Launch the interface\n",
    "# iface.launch(share=True)\n",
    "\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(theme=\"default\") as iface:\n",
    "    gr.Markdown(\"# EduGraphix\")\n",
    "    gr.Markdown(\"What are you exploring today? Let us enhance your journey with visual aids!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            input_text = gr.Textbox(label=\"Enter a prompt\", lines=5)\n",
    "            submit_button = gr.Button(\"Generate\", elem_id=\"submit-button\", size=\"sm\")\n",
    "            text_output = gr.Textbox(label=\"Textual Description\", lines=5)\n",
    "        with gr.Column(scale=1):\n",
    "            image_output = gr.Image(label=\"Generated Image\")\n",
    "    \n",
    "    # Set up the button action\n",
    "    submit_button.click(generate_text_and_image, inputs=input_text, outputs=[text_output, image_output])\n",
    "\n",
    "# Add custom CSS to style the button smaller\n",
    "iface.css = \"\"\"\n",
    "#submit-button {\n",
    "    padding: 5px 10px;\n",
    "    font-size: 12px;\n",
    "}\n",
    "\"\"\"\n",
    "iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
